{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('train_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments='Comment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sent(data):\n",
    "    sentences=sent_tokenize(data)\n",
    "    return sentences\n",
    "\n",
    "def tokenize_word(data):\n",
    "    words=word_tokenize(data)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[comments]=data[comments].apply(tokenize_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_data=data[comments]\n",
    "sentences=[]\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "for data in unigram_data:\n",
    "    for sent in data:\n",
    "        new_sent=sent.lower()\n",
    "        sentences.append(new_sent.translate(translator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sent=sentences\n",
    "bigram_sent=[]\n",
    "trigram_sent=[]\n",
    "quadgram_sent=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in sentences:\n",
    "    bigram_sent.append(sent)\n",
    "    trigram_sent.append(sent)\n",
    "    quadgram_sent.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_words=[]\n",
    "for sent in unigram_sent:\n",
    "    words=word_tokenize(sent)\n",
    "    unigram_words.append(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_words=unigram_words.copy()\n",
    "trigram_words=unigram_words.copy()\n",
    "quadgram_words = unigram_words.copy()\n",
    "\n",
    "for sent in bigram_words:\n",
    "    sent.append('</s>')\n",
    "    sent.insert(0,'<s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in trigram_words:\n",
    "    sent.append('</s>')\n",
    "    sent.append('</s>')\n",
    "    sent.insert(0,'<s>')\n",
    "    sent.insert(0,'<s>')\n",
    "\n",
    "for sent in quadgram_words:\n",
    "    sent.append('</s>')\n",
    "    sent.append('</s>')\n",
    "    sent.append('</s>')\n",
    "    sent.insert(0,'<s>')\n",
    "    sent.insert(0,'<s>')\n",
    "    sent.insert(0,'<s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "start_sent='<s>'\n",
    "end_sent='</s>'\n",
    "\n",
    "class unigram_model():\n",
    "  def __init__(self,sentences):\n",
    "    self.unigram_frequencies=dict()\n",
    "    self.vocabulary=set()\n",
    "    self.corpus_size=0\n",
    "    for sentence in sentences:\n",
    "      for word in sentence:\n",
    "        self.unigram_frequencies[word]=self.unigram_frequencies.get(word,0)+1\n",
    "        if word!=start_sent or  word!=end_sent:  \n",
    "         self.corpus_size+=1\n",
    "        if word not in self.vocabulary:\n",
    "         self.vocabulary.add(word)\n",
    "    self.vocab_size=len(self.unigram_frequencies)-2 #Not including start and end of sentence in vocabulary\n",
    "\n",
    "  def calculate_probability(self,word):\n",
    "    if word not in self.vocabulary:\n",
    "      return 0\n",
    "    return float(self.unigram_frequencies[word])/float(self.corpus_size)\n",
    "\n",
    "  def calculate_perplexity(self,word):\n",
    "    prob_word=self.calculate_probability(word)\n",
    "    if(prob_word==0):\n",
    "      return 10**(7)\n",
    "    perplexity=np.log2(float(1/prob_word))*(float(1/self.corpus_size))\n",
    "    return perplexity\n",
    "\n",
    "\n",
    "class bigram_model(unigram_model):\n",
    "  def __init__(self,sentences):\n",
    "    unigram_model.__init__(self,sentences)\n",
    "    self.bigram_frequencies=dict()\n",
    "    self.total_bigrams=0\n",
    "    for sentence in sentences:\n",
    "      prev_word=sentence[0]\n",
    "      for word in sentence[1:]:\n",
    "        self.bigram_frequencies[(prev_word,word)]=self.bigram_frequencies.get((prev_word,word),0)+1\n",
    "        self.total_bigrams+=1\n",
    "        prev_word=word\n",
    "\n",
    "    self.total_bigram_words=len(self.bigram_frequencies)\n",
    "\n",
    "  def calculate_probability(self,prev_word,word):\n",
    "    a=self.bigram_frequencies.get((prev_word,word),0)\n",
    "    b=self.unigram_frequencies.get(prev_word,0)\n",
    "\n",
    "    if b==0:\n",
    "      return 0\n",
    "    return float(a)/float(b)\n",
    "\n",
    "  def calculate_perplexity(self,prev_word,word):\n",
    "    prob_word=self.calculate_probability(prev_word,word)\n",
    "    if(prob_word==0):\n",
    "      return 10**(7)\n",
    "    perplexity=np.log2(float((1/prob_word)))*(float(1/self.total_bigrams))\n",
    "    return perplexity\n",
    "\n",
    "class trigram_model(bigram_model):\n",
    "    def __init__(self, sentences):\n",
    "        bigram_model.__init__(self, sentences)\n",
    "        self.trigram_frequencies = {}\n",
    "        self.total_trigrams=0\n",
    "        for sentence in sentences:\n",
    "            prev_word1 = sentence[0]\n",
    "            prev_word2 = sentence[1]\n",
    "            for word in sentence[2:]:\n",
    "              self.trigram_frequencies[(prev_word1, prev_word2, word)] = self.trigram_frequencies.get((prev_word1, prev_word2, word), 0) + 1\n",
    "              prev_word1 = prev_word2\n",
    "              prev_word2 = word\n",
    "              self.total_trigrams+=1\n",
    "\n",
    "        self.total_trigram_words = len(self.trigram_frequencies)\n",
    "\n",
    "    def calculate_probability(self, prev_word1, prev_word2, word):\n",
    "        trigram_frequency = self.trigram_frequencies.get((prev_word1, prev_word2, word), 0)\n",
    "        bigram_frequency = self.bigram_frequencies.get((prev_word2, word), 0)\n",
    "\n",
    "        if bigram_frequency == 0:\n",
    "            return 0\n",
    "        return float(trigram_frequency) / float(bigram_frequency)\n",
    "\n",
    "    def calculate_perplexity(self,prev_word1, prev_word2, word):\n",
    "      prob_word=self.calculate_probability(prev_word1, prev_word2, word)\n",
    "      if(prob_word==0):\n",
    "        return 10**(7)\n",
    "      perplexity=np.log2(float((1/prob_word)))*(float(1/self.total_trigrams))\n",
    "      return perplexity\n",
    "\n",
    "\n",
    "class quadgram_model(trigram_model):\n",
    "    def __init__(self, sentences):\n",
    "        trigram_model.__init__(self, sentences)\n",
    "        self.quadgram_frequencies = {}\n",
    "        self.total_quadgrams=0\n",
    "        for sentence in sentences:\n",
    "            prev_word1 = sentences[0]\n",
    "            prev_word2 = sentences[1]\n",
    "            prev_word3 = sentences[2]\n",
    "            for word in sentence[3:]:\n",
    "                quadgram = [prev_word1,prev_word2,prev_word3,word]\n",
    "                self.quadgram_frequencies[tuple(quadgram)] = self.quadgram_frequencies.get(tuple(quadgram), 0) + 1\n",
    "                prev_word1 = prev_word2\n",
    "                prev_word2 = prev_word3\n",
    "                prev_word3 = word\n",
    "                self.total_quadgrams+=1\n",
    "\n",
    "        self.total_quadgram_words = len(self.quadgram_frequencies)\n",
    "\n",
    "\n",
    "    def calculate_probability(self, prev_word1, prev_word2, prev_word3, word):\n",
    "        quadgram_frequency = self.quadgram_frequencies.get(tuple(prev_word1, prev_word2, prev_word3, word), 0)\n",
    "        trigram_frequency = self.trigram_frequencies.get(tuple(prev_word1, prev_word2, prev_word3), 0)\n",
    "\n",
    "        if trigram_frequency == 0:\n",
    "            return 0\n",
    "        return float(quadgram_frequency) / float(trigram_frequency)\n",
    "    \n",
    "    def calculate_perplexity(self,prev_word1, prev_word2, prev_word3, word):\n",
    "      prob_word=self.calculate_probability(prev_word1, prev_word2, prev_word3, word)\n",
    "      if(prob_word==0):\n",
    "        return 10**(7)\n",
    "      perplexity=np.log2(float((1/prob_word)))*(float(1/self.total_quadgrams))\n",
    "      return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('test_dataset.csv')\n",
    "test_comments='Comment'\n",
    "\n",
    "test_data[test_comments]=test_data[test_comments].apply(tokenize_sent)\n",
    "test_unigram_data=test_data[test_comments]\n",
    "test_sentences=[]\n",
    "for data in test_unigram_data:\n",
    "    for sent in data:\n",
    "        new_sent=sent.lower()\n",
    "        test_sentences.append(new_sent.translate(translator))\n",
    "\n",
    "test_unigram_sent=test_sentences\n",
    "test_unigram_words=[]\n",
    "for sent in test_unigram_sent:\n",
    "    words=word_tokenize(sent)\n",
    "    test_unigram_words.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIGRAM_MODEL=unigram_model(unigram_words)\n",
    "\n",
    "unigram_perplex=0\n",
    "count=0\n",
    "for data in test_unigram_words:\n",
    "    for word in data:\n",
    "        count+=1\n",
    "        unigram_perplex+=UNIGRAM_MODEL.calculate_perplexity(word)\n",
    "avg_perplex=unigram_perplex/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145340.5528644213"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_perplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1758750.3513784136"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIGRAM_MODEL=bigram_model(bigram_words)\n",
    "bigram_perplex=0\n",
    "count=0\n",
    "for data in test_unigram_words:\n",
    "    for i in range(len(data)-1):\n",
    "        count+=1\n",
    "        bigram_perplex+=BIGRAM_MODEL.calculate_perplexity(data[i],data[i+1])\n",
    "Avg_perplex=bigram_perplex/count\n",
    "Avg_perplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class N_Gram(unigram_model):\n",
    "    def __init__(self,sentences,n):\n",
    "        if(n==1):\n",
    "            self.model=unigram_model(sentences)\n",
    "        if(n==2):\n",
    "            self.model=bigram_model(sentences)\n",
    "        if(n==3):\n",
    "            self.model=trigram_model(sentences)\n",
    "        if(n==4):\n",
    "            self.model=quadgram_model(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7380\\3890325059.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_bi_gram_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mN_Gram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigram_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_tri_gram_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mN_Gram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrigram_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtest_quad_gram_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mN_Gram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquadgram_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7380\\1505721994.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, n)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrigram_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquadgram_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7380\\3085792404.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[0mquadgram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprev_word1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprev_word2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprev_word3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquadgram_frequencies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquadgram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquadgram_frequencies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquadgram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m                 \u001b[0mprev_word1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_word2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[0mprev_word2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_word3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "test_uni_gram_model=N_Gram(unigram_words,1)\n",
    "test_bi_gram_model=N_Gram(bigram_words,2)\n",
    "test_tri_gram_model=N_Gram(trigram_words,3)\n",
    "test_quad_gram_model=N_Gram(quadgram_words,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021763939748329936\n",
      "0.0656356214730611\n",
      "0.03412073490813648\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(test_uni_gram_model.model.calculate_probability('the'))\n",
    "print(test_bi_gram_model.model.calculate_probability('is','the'))\n",
    "print(test_tri_gram_model.model.calculate_probability('seems','to','me'))\n",
    "print(test_quad_gram_model.model.calculate_probability('seems','to','me','that'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_quad_gram_model=N_Gram(quadgram_words,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
