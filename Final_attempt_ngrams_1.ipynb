{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3555,"status":"ok","timestamp":1695152608135,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"f6liLDpjW4qE","outputId":"e4d6b7ac-56f5-46ae-f25c-440bfd56de94"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/sachin/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import copy\n","import string\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n","from scipy.optimize import minimize,curve_fit\n","import matplotlib.pyplot as plt\n","from nltk.stem import WordNetLemmatizer"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1243,"status":"ok","timestamp":1695152801817,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"19yqR65gW4qH"},"outputs":[],"source":["train_df = pd.read_csv('train_dataset.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1695152787092,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"U3yhmj5R-qPk"},"outputs":[],"source":["test_df = pd.read_csv('test_dataset.csv')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":414,"status":"ok","timestamp":1695152739677,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"4qEDBVBvW4qI"},"outputs":[],"source":["comments='Comment'"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1695152740418,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"BJylx-ETorJG"},"outputs":[],"source":["from nltk.corpus import stopwords\n","lemmatizer = WordNetLemmatizer()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1695152741099,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"esSo8yWnozWl","outputId":"95b46378-8fd2-415e-cd14-c434c8ddc290"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /home/sachin/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('stopwords')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1695152741100,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"09cIWKvEouzv"},"outputs":[],"source":["stops = set(stopwords.words('english'))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":9420,"status":"ok","timestamp":1695152814324,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"Ge9UAiUF-m-N"},"outputs":[],"source":["train_sentences = []\n","train_list=[]\n","\n","for comment in train_df['Comment']:\n","    sentences = sent_tokenize(comment)\n","    train_list.append(sentences)\n","for data in train_list:\n","    for sent in data:\n","        train_sentences.append(sent)\n","test_sentences = []\n","test_list=[]\n","for comment in test_df['Comment']:\n","    sentences = sent_tokenize(comment)\n","    test_list.append(sentences)\n","for data in test_list:\n","    for sent in data:\n","        test_sentences.append(sent)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1566,"status":"ok","timestamp":1695153022201,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"eEZ7904s-m7j"},"outputs":[],"source":["translator = str.maketrans('', '', string.punctuation)\n","train_sentences_temp=[]\n","for sent in train_sentences:\n","    sentence_without_commas = sent\n","    sentence_without_commas = sentence_without_commas.replace(',', '')\n","    sentence_without_commas = sentence_without_commas.replace(',', '')\n","    sentence_without_commas = sentence_without_commas.replace('.', '')\n","    sentence_without_commas = sentence_without_commas.replace('!', '')\n","    sentence_without_commas = sentence_without_commas.replace('?', '')\n","    sentence_without_commas = sentence_without_commas.replace('-', '')\n","    sentence_without_commas = sentence_without_commas.replace('\"', '')\n","    sentence_without_commas = sentence_without_commas.replace(')', '')\n","    sentence_without_commas = sentence_without_commas.replace('(', '')\n","    sentence_without_commas = sentence_without_commas.replace(']', '')\n","    sentence_without_commas = sentence_without_commas.replace('[', '')\n","    sentence_without_commas = sentence_without_commas.replace(\"'\", '')\n","    sentence_without_commas = sentence_without_commas.replace('{', '')\n","    sentence_without_commas = sentence_without_commas.replace('}', '')\n","    sentence_without_commas = sentence_without_commas.replace('%', '')\n","    sentence_without_commas = sentence_without_commas.replace('$', '')\n","    train_sentences_temp.append(sentence_without_commas)\n","train_sentences=train_sentences_temp\n","test_sentences_temp=[]\n","for sent in test_sentences:\n","    sentence_without_commas = sent\n","    sentence_without_commas = sentence_without_commas.replace(',', '')\n","    sentence_without_commas = sentence_without_commas.replace(',', '')\n","    sentence_without_commas = sentence_without_commas.replace('.', '')\n","    sentence_without_commas = sentence_without_commas.replace('!', '')\n","    sentence_without_commas = sentence_without_commas.replace('?', '')\n","    sentence_without_commas = sentence_without_commas.replace('-', '')\n","    sentence_without_commas = sentence_without_commas.replace('\"', '')\n","    sentence_without_commas = sentence_without_commas.replace(')', '')\n","    sentence_without_commas = sentence_without_commas.replace('(', '')\n","    sentence_without_commas = sentence_without_commas.replace(']', '')\n","    sentence_without_commas = sentence_without_commas.replace('[', '')\n","    sentence_without_commas = sentence_without_commas.replace(\"'\", '')\n","    sentence_without_commas = sentence_without_commas.replace('{', '')\n","    sentence_without_commas = sentence_without_commas.replace('}', '')\n","    sentence_without_commas = sentence_without_commas.replace('%', '')\n","    sentence_without_commas = sentence_without_commas.replace('$', '')\n","    test_sentences_temp.append(sentence_without_commas)\n","test_sentences=test_sentences_temp\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1695153090092,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"9oG1z8TP_0OF","outputId":"e69a5ad1-e9e3-4ce6-bb52-a249cacf9e14"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /home/sachin/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('wordnet')"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":77815,"status":"ok","timestamp":1695153170306,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"p8KEw1CQ_mYH"},"outputs":[],"source":["train_unigram = []\n","for sent in train_sentences:\n","    words = word_tokenize(sent)\n","    proc_words = []\n","    for word in words:\n","        if(word.isalpha() and word not in stops): proc_words.append(lemmatizer.lemmatize(word.lower()))\n","    if len(proc_words)!=0:\n","        train_unigram.append(proc_words)\n","test_unigram = []\n","for sent in test_sentences:\n","    words = word_tokenize(sent)\n","    proc_words = []\n","    for word in words:\n","        if(word.isalpha() and word not in stops): proc_words.append(lemmatizer.lemmatize(word.lower()))\n","    if len(proc_words)!=0:\n","        test_unigram.append(proc_words)\n","\n","train_bigram = copy.deepcopy(train_unigram)\n","test_bigram = copy.deepcopy(test_unigram)\n","train_trigram = copy.deepcopy(train_unigram)\n","test_trigram = copy.deepcopy(test_unigram)\n","train_quadgram = copy.deepcopy(train_unigram)\n","test_quadgram = copy.deepcopy(test_unigram)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":441,"status":"ok","timestamp":1695153177223,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"BWUfezwt-m4j"},"outputs":[],"source":["for sent in train_bigram:\n","    sent.append('</s>')\n","    sent.insert(0, '<s>')\n","for sent in test_bigram:\n","    sent.append('</s>')\n","    sent.insert(0, '<s>')"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":946,"status":"ok","timestamp":1695153180019,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"K5ALtZ2P_7yV"},"outputs":[],"source":["for sent in train_trigram:\n","    sent.append('</s>')\n","    sent.insert(0, '<s>')\n","    sent.append('</s>')\n","    sent.insert(0, '<s>')\n","for sent in test_trigram:\n","    sent.append('</s>')\n","    sent.insert(0, '<s>')\n","    sent.append('</s>')\n","    sent.insert(0, '<s>')"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1695153180020,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"aUb5Op34_9ZU"},"outputs":[],"source":["for sent in train_quadgram:\n","    sent.append('</s>')\n","    sent.insert(0, '<s>')\n","    sent.append('</s>')\n","    sent.insert(0, '<s>')\n","    sent.append('</s>')\n","    sent.insert(0, '<s>')\n","for sent in test_quadgram:\n","    sent.append('</s>')\n","    sent.insert(0, '<s>')\n","    sent.append('</s>')\n","    sent.insert(0, '<s>')\n","    sent.append('</s>')\n","    sent.insert(0, '<s>')"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1695153183151,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"QLT5bMeWW4qM"},"outputs":[],"source":["import numpy as np\n","\n","start_sent = \"<s>\"\n","end_sent = \"</s>\"\n","\n","\n","class unigram_model:\n","    def __init__(self, sentences):\n","        self.unigram_frequencies = dict()\n","        self.good_turing_count = dict()\n","        self.vocabulary = set()\n","        self.corpus_size = 0\n","        for sentence in sentences:\n","            for word in sentence:\n","                self.unigram_frequencies[word] = (\n","                    self.unigram_frequencies.get(word, 0) + 1\n","                )\n","                if word != start_sent or word != end_sent:\n","                    self.corpus_size += 1\n","                if word not in self.vocabulary:\n","                    self.vocabulary.add(word)\n","        self.vocab_size = (\n","            len(self.unigram_frequencies) - 2\n","        )  # Not including start and end of sentence in vocabulary\n","\n","    def calculate_probability(self, word):\n","        if word not in self.vocabulary:\n","            return 0\n","        return float(self.unigram_frequencies[word]) / float(self.corpus_size)\n","\n","    def calculate_perplexity(self, word):\n","        prob_word = self.calculate_probability(word)\n","        if prob_word == 0:\n","            return 10 ** (7)\n","        perplexity = np.log2(float(1 / prob_word)) * (float(1 / self.corpus_size))\n","        return perplexity\n","\n","    def calculate_probability_smooth(self, word, k):\n","        return float(self.unigram_frequencies[word] + float(k)) / (\n","            float(self.corpus_size) + k * float(self.vocab_size)\n","        )\n","\n","    def calculate_new_word_count(self,diction:dict):\n","        # freq_to_words_dict : {Key:Number of words occured that many times, Value:List of words that occured that many times}\n","        freq_to_words_dict = dict()\n","\n","        for word in diction.keys():\n","            if(diction[word] in freq_to_words_dict.keys()):\n","                freq_to_words_dict[diction[word]] += [word]\n","            else:\n","                freq_to_words_dict[diction[word]] = [word]\n","        # freq_to_words_dict[0] = [\"<unk>\"]\n","        # new_word_count : {Key:Word, Value:New count of word according to good turing}\n","        x_values = list(freq_to_words_dict.keys())\n","        x_values_2=[]\n","        y_values = []\n","        for i in x_values:\n","            if(i+1 not in freq_to_words_dict.keys()):\n","                x_values_2.append(i)\n","                y_values.append(len(freq_to_words_dict[i]))\n","        x_values = np.array(x_values_2)\n","        y_values = np.array(y_values)\n","        x_values_3=x_values.argsort()[:5]\n","        x_values=x_values[x_values_3]\n","        y_values=y_values[x_values_3]\n","        # print(x_values)\n","\n","        def power_law(x, C, alpha):\n","            return C * np.power(x, -alpha)\n","\n","        params, _ = curve_fit(power_law, x_values, y_values)\n","\n","        new_word_count = dict()\n","        keys = freq_to_words_dict.keys()\n","        for i in freq_to_words_dict.keys():\n","            for word in freq_to_words_dict[i]:\n","                if i + 1 in freq_to_words_dict.keys():\n","                    new_word_count[word] = (i + 1) * (\n","                        len(freq_to_words_dict[i + 1]) / len(freq_to_words_dict[i])\n","                    )\n","                else:\n","                    new_word_count[word] = (i + 1) * (\n","                        power_law(float(i + 1), params[0], params[1])\n","                        / power_law(float(i), params[0], params[1])\n","                    )\n","                # new_word_count[word] = (\n","                #     (self.unigram_frequencies[word] + 1) * power_law / keys[i]\n","                # )\n","        # Keeping the word count same for the most frequent words\n","        # Calculating the probability of <unk>, <unk> is which has not appeared in the corpus\n","        new_word_count[\"<unk>\"] = len(freq_to_words_dict[1]) / self.corpus_size\n","        self.good_turing_count = new_word_count\n","\n","    def calculate_probability_good_smooth(self, word):\n","      new_word_count = self.good_turing_count\n","      if word not in new_word_count:\n","          return new_word_count[\"<unk>\"]\n","      return new_word_count[word] / self.corpus_size\n","\n","\n","class bigram_model(unigram_model):\n","    def __init__(self, sentences):\n","        unigram_model.__init__(self, sentences)\n","        self.bigram_frequencies = dict()\n","        self.total_bigrams = 0\n","        for sentence in sentences:\n","            prev_word = sentence[0]\n","            for word in sentence[1:]:\n","                self.bigram_frequencies[(prev_word, word)] = (\n","                    self.bigram_frequencies.get((prev_word, word), 0) + 1\n","                )\n","                self.total_bigrams += 1\n","                prev_word = word\n","\n","        self.total_bigram_words = len(self.bigram_frequencies)\n","\n","    def calculate_probability(self, prev_word, word):\n","        a = self.bigram_frequencies.get((prev_word, word), 0)\n","        b = self.unigram_frequencies.get(prev_word, 0)\n","\n","        if b == 0:\n","            return 0\n","        return float(a) / float(b)\n","\n","    def calculate_perplexity(self, prev_word, word):\n","        prob_word = self.calculate_probability(prev_word, word)\n","        if prob_word == 0:\n","            return 10 ** (7)\n","        perplexity = np.log2(float((1 / prob_word))) * (float(1 / self.total_bigrams))\n","        return perplexity\n","\n","    def calculate_probability_smooth(self, prev_word, word, k, k_prev):\n","        a = self.bigram_frequencies.get((prev_word, word), 0)\n","        b = self.unigram_frequencies.get(prev_word, 0)\n","\n","        return (float(a) + float(k)) / (float(b) + float(k_prev) + k * self.vocab_size)\n","\n","\n","class trigram_model(bigram_model):\n","    def __init__(self, sentences):\n","        bigram_model.__init__(self, sentences)\n","        self.trigram_frequencies = {}\n","        self.total_trigrams = 0\n","        for sentence in sentences:\n","            prev_word1 = sentence[0]\n","            prev_word2 = sentence[1]\n","            for word in sentence[2:]:\n","                self.trigram_frequencies[(prev_word1, prev_word2, word)] = (\n","                    self.trigram_frequencies.get((prev_word1, prev_word2, word), 0) + 1\n","                )\n","                prev_word1 = prev_word2\n","                prev_word2 = word\n","                self.total_trigrams += 1\n","\n","        self.total_trigram_words = len(self.trigram_frequencies)\n","\n","    def calculate_probability(self, prev_word1, prev_word2, word):\n","        trigram_frequency = self.trigram_frequencies.get(\n","            (prev_word1, prev_word2, word), 0\n","        )\n","        bigram_frequency = self.bigram_frequencies.get((prev_word2, word), 0)\n","\n","        if bigram_frequency == 0:\n","            return 0\n","        return float(trigram_frequency) / float(bigram_frequency)\n","\n","    def calculate_perplexity(self, prev_word1, prev_word2, word):\n","        prob_word = self.calculate_probability(prev_word1, prev_word2, word)\n","        if prob_word == 0:\n","            return 10 ** (7)\n","        perplexity = np.log2(float((1 / prob_word))) * (float(1 / self.total_trigrams))\n","        return perplexity\n","\n","    def calculate_probability_smooth(self, prev_word1, prev_word2, word, k, k_prev):\n","        trigram_frequency = self.trigram_frequencies.get(\n","            (prev_word1, prev_word2, word), 0\n","        )\n","        bigram_frequency = self.bigram_frequencies.get((prev_word2, word), 0)\n","\n","        return (float(trigram_frequency) + float(k)) / (\n","            float(bigram_frequency) + float(k_prev) + k * self.vocab_size\n","        )\n","\n","\n","class quadgram_model(trigram_model):\n","    def __init__(self, sentences):\n","        trigram_model.__init__(self, sentences)\n","        self.quadgram_frequencies = {}\n","        self.total_quadgrams = 0\n","        for sentence in sentences:\n","            prev_word1 = sentence[0]\n","            prev_word2 = sentence[1]\n","            prev_word3 = sentence[2]\n","            for word in sentence[3:]:\n","                quadgram = (prev_word1, prev_word2, prev_word3, word)\n","                self.quadgram_frequencies[quadgram] = (\n","                    self.quadgram_frequencies.get(quadgram, 0) + 1\n","                )\n","                prev_word1 = prev_word2\n","                prev_word2 = prev_word3\n","                prev_word3 = word\n","                self.total_quadgrams += 1\n","\n","        self.total_quadgram_words = len(self.quadgram_frequencies)\n","\n","    def calculate_probability(self, prev_word1, prev_word2, prev_word3, word):\n","        quadgram_frequency = self.quadgram_frequencies.get(\n","            (prev_word1, prev_word2, prev_word3, word), 0\n","        )\n","        trigram_frequency = self.trigram_frequencies.get(\n","            (prev_word1, prev_word2, prev_word3), 0\n","        )\n","\n","        if trigram_frequency == 0:\n","            return 0\n","        return float(quadgram_frequency) / float(trigram_frequency)\n","\n","    def calculate_perplexity(self, prev_word1, prev_word2, prev_word3, word):\n","        prob_word = self.calculate_probability(prev_word1, prev_word2, prev_word3, word)\n","        if prob_word == 0:\n","            return 10 ** (7)\n","        perplexity = np.log2(float((1 / prob_word))) * (float(1 / self.total_quadgrams))\n","        return perplexity\n","\n","    def calculate_probability_smooth(\n","        self, prev_word1, prev_word2, prev_word3, word, k, k_prev\n","    ):\n","        quadgram_frequency = self.quadgram_frequencies.get(\n","            (prev_word1, prev_word2, prev_word3, word), 0\n","        )\n","        trigram_frequency = self.trigram_frequencies.get(\n","            (prev_word1, prev_word2, prev_word3), 0\n","        )\n","\n","        return (float(quadgram_frequency) + float(k)) / (\n","            float(trigram_frequency) + float(k_prev) + k * self.vocab_size\n","        )"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"4nLD2UELW4qP"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_8456/1632651415.py:12: RuntimeWarning: divide by zero encountered in log2\n","  unigram_perplex += np.log2(UNIGRAM_MODEL.calculate_probability(word))\n"]}],"source":["UNIGRAM_MODEL=unigram_model(train_unigram)\n","\n","count=0\n","total_perplex = 0\n","for data in test_unigram:\n","\n","    count+=1\n","    n = len(data)\n","    if(n == 0): continue\n","    unigram_perplex=0\n","    for word in data:\n","        unigram_perplex += np.log2(UNIGRAM_MODEL.calculate_probability(word))\n","\n","    unigram_perplex *= (-1/n)\n","    final_perplex = 2 ** unigram_perplex\n","    total_perplex += final_perplex\n","\n","\n","avg_perplex = total_perplex/count"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"lMFOB-pZW4qP"},"outputs":[{"data":{"text/plain":["inf"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["avg_perplex"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"2cRuczKsW4qQ"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_8456/2328182941.py:11: RuntimeWarning: divide by zero encountered in log2\n","  bigram_perplex+=np.log2(BIGRAM_MODEL.calculate_probability(data[i],data[i+1]))\n"]},{"data":{"text/plain":["inf"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["BIGRAM_MODEL=bigram_model(train_bigram)\n","total_perplex=0\n","count=0\n","for data in test_bigram:\n","    count+= 1\n","    bigram_perplex = 0\n","    n = len(data)\n","    if(n < 2): continue\n","\n","    for i in range(len(data)-1):\n","        bigram_perplex+=np.log2(BIGRAM_MODEL.calculate_probability(data[i],data[i+1]))\n","\n","    bigram_perplex *= (-1/n)\n","    final_perplex = 2 ** bigram_perplex\n","    total_perplex += final_perplex\n","\n","\n","Avg_perplex=total_perplex/count\n","Avg_perplex"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"7n4GlTtyW4qQ"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_8456/3141926806.py:12: RuntimeWarning: divide by zero encountered in log2\n","  trigram_perplex+=np.log2(TRIGRAM_MODEL.calculate_probability(data[i],data[i+1], data[i+2]))\n"]},{"data":{"text/plain":["inf"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["TRIGRAM_MODEL=trigram_model(train_trigram)\n","total_perplex=0\n","count=0\n","\n","for data in test_trigram:\n","    count+= 1\n","    trigram_perplex = 0\n","    n = len(data)\n","    if(n < 3): continue\n","\n","    for i in range(len(data)-2):\n","        trigram_perplex+=np.log2(TRIGRAM_MODEL.calculate_probability(data[i],data[i+1], data[i+2]))\n","\n","    trigram_perplex *= (-1/n)\n","    final_perplex = 2 ** trigram_perplex\n","    total_perplex += final_perplex\n","\n","\n","Avg_perplex=total_perplex/count\n","Avg_perplex"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"paZDwM3bW4qR"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_8456/3850654556.py:12: RuntimeWarning: divide by zero encountered in log2\n","  quadgram_perplex+=np.log2(QUADGRAM_MODEL.calculate_probability(data[i],data[i+1], data[i+2] , data[i+3]))\n"]},{"data":{"text/plain":["inf"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["QUADGRAM_MODEL=quadgram_model(train_quadgram)\n","total_perplex=0\n","count=0\n","\n","for data in test_quadgram:\n","    count+= 1\n","    quadgram_perplex = 0\n","    n = len(data)\n","    if(n < 4): continue\n","\n","    for i in range(len(data)-3):\n","        quadgram_perplex+=np.log2(QUADGRAM_MODEL.calculate_probability(data[i],data[i+1], data[i+2] , data[i+3]))\n","\n","    quadgram_perplex *= (-1/n)\n","    final_perplex = 2 ** quadgram_perplex\n","    total_perplex += final_perplex\n","\n","\n","Avg_perplex=total_perplex/count\n","Avg_perplex"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":1492,"status":"ok","timestamp":1695153224647,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"p4KZvxNcW4qR"},"outputs":[],"source":["UNIGRAM_MODEL=unigram_model(train_unigram)\n","\n","for data in test_unigram:\n","    for word in data:\n","        if word not in UNIGRAM_MODEL.vocabulary:\n","            UNIGRAM_MODEL.vocabulary.add(word)\n","            UNIGRAM_MODEL.vocab_size += 1\n","            UNIGRAM_MODEL.unigram_frequencies[word] = 0"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":443,"status":"ok","timestamp":1695153232974,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"XNCXme88W4qS"},"outputs":[],"source":["def uni(k):\n","\n","    count=0\n","    total_perplex = 0\n","    for data_ in test_unigram:\n","\n","        count+=1\n","        n = len(data_)\n","        if(n == 0): continue\n","        unigram_perplex=0\n","        for word in data_:\n","            unigram_perplex += np.log2(UNIGRAM_MODEL.calculate_probability_smooth(word , k))\n","\n","        unigram_perplex *= (-1/float(n))\n","        final_perplex = 2 ** unigram_perplex\n","        total_perplex += final_perplex\n","\n","    avg_perplex = total_perplex/float(count)\n","    return avg_perplex"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1695153237934,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"RbJ4iXEfW4qS"},"outputs":[],"source":["from scipy.optimize import minimize"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1695153237935,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"muat3-YXW4qS"},"outputs":[],"source":["def callback(xk):\n","    print(xk)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":45440,"status":"error","timestamp":1695153287148,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"xieYThKFW4qT","outputId":"1797fa93-fb83-417a-a29b-3ff69d5054db"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.37064447]\n","[0.44503719]\n","[0.63115028]\n","[0.84244655]\n","[1.15868659]\n","[1.58415816]\n","[2.17805797]\n","[2.98456507]\n","[4.06187246]\n","[5.44407332]\n","[7.11149037]\n","[8.92991313]\n","[10.]\n"]}],"source":["result = minimize(uni , 0.001 , tol = 1e-5 , callback = callback, bounds = [(0.0001 , 10)])\n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1064,"status":"ok","timestamp":1695153321143,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"KiakuHijdXdN","outputId":"cad5d489-9dfc-4fe8-8d5a-74eac0a0a50f"},"outputs":[{"data":{"text/plain":["8213.009889641138"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["k_uni = 10\n","uni(k_uni)"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":6435,"status":"ok","timestamp":1695153358060,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"NJyius6UXkGn"},"outputs":[],"source":["BIGRAM_MODEL=bigram_model(train_bigram)\n","\n","for data in test_bigram:\n","    n = len(data)\n","    for word in data:\n","        if word not in BIGRAM_MODEL.vocabulary:\n","            BIGRAM_MODEL.vocabulary.add(word)\n","            BIGRAM_MODEL.vocab_size += 1\n","\n","    for i in range(n-1):\n","\n","        if(data[i], data[i+1]) not in BIGRAM_MODEL.bigram_frequencies:\n","            BIGRAM_MODEL.bigram_frequencies[(data[i], data[i+1])] = 0"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1695153359811,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"xbZ_9WSKW4qV"},"outputs":[],"source":["\n","def bi(k):\n","\n","    total_perplex=0\n","    count=0\n","\n","    for data in test_bigram:\n","        count+= 1\n","        bigram_perplex = 0\n","        n = len(data)\n","        if(n < 2): continue\n","\n","        for i in range(len(data)-1):\n","\n","            bigram_perplex+=np.log2(BIGRAM_MODEL.calculate_probability_smooth(data[i],data[i+1] , k ,k_uni ))\n","\n","        bigram_perplex *= (-1/n)\n","        final_perplex = 2 ** bigram_perplex\n","        total_perplex += final_perplex\n","\n","\n","    Avg_perplex=total_perplex/count\n","    return Avg_perplex\n"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":544337,"status":"ok","timestamp":1695153908655,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"8syjTUAmXuH-","outputId":"50bf122c-18c9-4394-9a7a-6bde87c284ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1.67172134e-05]\n","[1.84732615e-05]\n","[2.80747062e-05]\n","[3.7494697e-05]\n","[5.25929876e-05]\n","[7.24219734e-05]\n","[0.0001005]\n","[0.00013913]\n","[0.00019293]\n","[0.00026758]\n","[0.00037141]\n","[0.00051574]\n","[0.00071624]\n","[0.00099409]\n","[0.0013774]\n","[0.00190211]\n","[0.00261162]\n","[0.00355294]\n","[0.00476611]\n","[0.00626179]\n","[0.00798341]\n","[0.00976209]\n","[0.01130675]\n","[0.01231719]\n","[0.01273346]\n","[0.01281533]\n"]}],"source":["result = minimize(bi , 1e-8 , tol = 1e-5 , callback = callback , bounds = [(1e-8 , 1)])"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2627,"status":"ok","timestamp":1695153921189,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"eWBq5tN_dujG","outputId":"2f3025d8-cc31-4135-f908-db715654e273"},"outputs":[{"data":{"text/plain":["1825.346134736325"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["k_bi = 0.01303768\n","bi(k_bi)\n"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":9188,"status":"ok","timestamp":1695153969474,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"4sIW5UXBW4qW"},"outputs":[],"source":["TRIGRAM_MODEL=trigram_model(train_trigram)\n","\n","y = []\n","for data in test_trigram:\n","    n = len(data)\n","    for word in data:\n","        if word not in TRIGRAM_MODEL.vocabulary:\n","            TRIGRAM_MODEL.vocabulary.add(word)\n","            TRIGRAM_MODEL.vocab_size += 1\n","\n","    for i in range(n-2):\n","        if(data[i], data[i+1], data[i+2]) not in TRIGRAM_MODEL.trigram_frequencies:\n","            TRIGRAM_MODEL.trigram_frequencies[(data[i], data[i+1] , data[i+2])] = 0"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":391,"status":"ok","timestamp":1695153972307,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"30VV0YzDW4qW"},"outputs":[],"source":["def tri(k):\n","\n","    total_perplex=0\n","    count=0\n","\n","    for data in test_trigram:\n","        count+= 1\n","        trigram_perplex = 0\n","        n = len(data)\n","        if(n < 3): continue\n","\n","        for i in range(len(data)-2):\n","            trigram_perplex+=np.log2(TRIGRAM_MODEL.calculate_probability_smooth(data[i],data[i+1], data[i+2] ,k , k_bi))\n","\n","        trigram_perplex *= (-1/n)\n","        final_perplex = 2 ** trigram_perplex\n","        total_perplex += final_perplex\n","\n","\n","    Avg_perplex=total_perplex/count\n","    return Avg_perplex"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112396,"status":"ok","timestamp":1695154089558,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"HEoGAEoEYEQ9","outputId":"e01e191f-8144-4f1c-a170-2a48dd12dd80"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.00115661]\n","[0.00114889]\n"]}],"source":["result = minimize(tri , 0.001 , tol = 1e-5 , callback = callback , bounds = [(0.0001 , 1)])"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2214,"status":"ok","timestamp":1695154102933,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"tKBWnv-mgUlC","outputId":"f3d14513-07a6-427f-f8ed-e56d81b3702f"},"outputs":[{"data":{"text/plain":["2334.3734379988905"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["k_tri = 0.00114889\n","tri(k_tri)\n"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":14635,"status":"ok","timestamp":1695154131543,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"rIBjqa8VW4qX"},"outputs":[],"source":["QUADGRAM_MODEL= quadgram_model(train_quadgram)\n","\n","y = []\n","for data in test_quadgram:\n","    n = len(data)\n","    for word in data:\n","        if word not in QUADGRAM_MODEL.vocabulary:\n","            QUADGRAM_MODEL.vocabulary.add(word)\n","            QUADGRAM_MODEL.vocab_size += 1\n","\n","    for i in range(n-3):\n","        if(data[i], data[i+1], data[i+2] , data[i+3]) not in QUADGRAM_MODEL.quadgram_frequencies:\n","            QUADGRAM_MODEL.quadgram_frequencies[(data[i], data[i+1] , data[i+2] , data[i+3])] = 0"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1695154142290,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"BUxeWvd7W4qY"},"outputs":[],"source":["def quad(k):\n","\n","    total_perplex=0\n","    count=0\n","\n","    for data in test_quadgram:\n","        count+= 1\n","        quadgram_perplex = 0\n","        n = len(data)\n","        if(n < 4): continue\n","\n","        for i in range(len(data)-3):\n","            quadgram_perplex += np.log2(QUADGRAM_MODEL.calculate_probability_smooth(data[i],data[i+1], data[i+2],data[i+3] ,k, k_tri))\n","\n","        quadgram_perplex *= (-1/n)\n","        final_perplex = 2 ** quadgram_perplex\n","        total_perplex += final_perplex\n","\n","\n","    Avg_perplex=total_perplex/count\n","    return Avg_perplex"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":138358,"status":"ok","timestamp":1695154285396,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"3FsCjuyJYWKf","outputId":"b3debcfd-6342-47e8-d10e-e51ddf4b80f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.00064617]\n","[0.00043052]\n","[0.00040645]\n","[0.00040418]\n"]}],"source":["result = minimize(quad , 0.001 , tol = 1e-5 , callback = callback , bounds = [(0.00001 , 1)])"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4011,"status":"ok","timestamp":1695154301113,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"UFUotK3RiQXD","outputId":"d1dafc82-a878-45a8-b772-319d8fddb702"},"outputs":[{"data":{"text/plain":["1882.1098191057736"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["quad(0.00040418)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HG9zYRr-W4qY"},"outputs":[],"source":["class N_Gram(unigram_model):\n","    def __init__(self,sentences,n):\n","        if(n==1):\n","            self.model=unigram_model(sentences)\n","        if(n==2):\n","            self.model=bigram_model(sentences)\n","        if(n==3):\n","            self.model=trigram_model(sentences)\n","        if(n==4):\n","            self.model=quadgram_model(sentences)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1694995641551,"user":{"displayName":"Rachit Verma","userId":"02514786626547192172"},"user_tz":0},"id":"wYNGSOVOW4qZ","outputId":"b145b272-63b4-479f-8a65-c76264e57d31"},"outputs":[{"data":{"text/plain":["{('<s>', '<s>'): 1345530,\n"," ('<s>', 'how'): 1916,\n"," ('how', 'about'): 177,\n"," ('about', 'you'): 185,\n"," ('you', 'let'): 19,\n"," ('let', 'people'): 80,\n"," ('people', 'believe'): 57,\n"," ('believe', 'what'): 71,\n"," ('what', 'they'): 755,\n"," ('they', 'want'): 600,\n"," ('want', 'to'): 2618,\n"," ('to', 'believe'): 437,\n"," ('believe', 'in'): 539,\n"," ('in', 'a'): 3161,\n"," ('a', 'hard'): 110,\n"," ('hard', 'time'): 61,\n"," ('time', 'like'): 15,\n"," ('like', 'this'): 1091,\n"," ('this', '</s>'): 2322,\n"," ('</s>', '</s>'): 1345530,\n"," ('<s>', 'stop'): 309,\n"," ('stop', 'causing'): 5,\n"," ('causing', 'more'): 11,\n"," ('more', 'division'): 8,\n"," ('division', 'when'): 5,\n"," ('when', 'the'): 804,\n"," ('the', 'world'): 2614,\n"," ('world', 'is'): 240,\n"," ('is', 'already'): 170,\n"," ('already', 'divided'): 6,\n"," ('divided', '</s>'): 15,\n"," ('<s>', 'seems'): 176,\n"," ('seems', 'to'): 383,\n"," ('to', 'me'): 762,\n"," ('me', 'that'): 223,\n"," ('that', 'you'): 1657,\n"," ('you', 'are'): 3971,\n"," ('are', 'the'): 1337,\n"," ('the', 'naive'): 5,\n"," ('naive', 'one'): 2,\n"," ('one', '</s>'): 667,\n"," ('<s>', 'you'): 7319,\n"," ('you', 'have'): 3740,\n"," ('have', 'not'): 185,\n"," ('not', 'responded'): 2,\n"," ('responded', 'with'): 10,\n"," ('with', 'any'): 88,\n"," ('any', 'sources'): 17,\n"," ('sources', '</s>'): 73,\n"," ('<s>', 'im'): 2631,\n"," ('im', 'aware'): 22,\n"," ('aware', 'of'): 485,\n"," ('of', 'the'): 12737,\n"," ('the', 'sources'): 22,\n"," ('sources', 'you'): 7,\n"," ('are', 'going'): 369,\n"," ('going', 'to'): 2108,\n"," ('to', 'bring'): 236,\n"," ('bring', 'that'): 18,\n"," ('that', 'actually'): 44,\n"," ('actually', 'nonmuslims'): 2,\n"," ('nonmuslims', 'and'): 4,\n"," ('and', 'exmuslims'): 3,\n"," ('exmuslims', 'like'): 2,\n"," ('like', 'to'): 533,\n"," ('bring', '</s>'): 11,\n"," ('<s>', 'they'): 5325,\n"," ('they', 'completely'): 10,\n"," ('completely', 'take'): 2,\n"," ('take', 'the'): 263,\n"," ('the', 'verses'): 10,\n"," ('verses', 'and'): 8,\n"," ('and', 'the'): 3980,\n"," ('the', 'hadiths'): 7,\n"," ('hadiths', 'out'): 2,\n"," ('out', 'of'): 2095,\n"," ('of', 'context'): 74,\n"," ('context', '</s>'): 140,\n"," ('<s>', 'i'): 23293,\n"," ('i', 'dont'): 3429,\n"," ('dont', 'really'): 159,\n"," ('really', 'care'): 61,\n"," ('care', 'what'): 42,\n"," ('what', 'fence'): 1,\n"," ('fence', 'you'): 2,\n"," ('you', 'stand'): 24,\n"," ('stand', 'or'): 4,\n"," ('or', 'how'): 61,\n"," ('how', 'many'): 488,\n"," ('many', 'somersaults'): 1,\n"," ('somersaults', 'you'): 1,\n"," ('you', 'want'): 985,\n"," ('to', 'do'): 2596,\n"," ('do', 'over'): 1,\n"," ('over', 'it'): 64,\n"," ('it', 'i'): 127,\n"," ('i', 'was'): 2223,\n"," ('was', 'simply'): 32,\n"," ('simply', 'telling'): 3,\n"," ('telling', 'op'): 1,\n"," ('op', 'that'): 5,\n"," ('that', 'he'): 604,\n"," ('he', 'should'): 140,\n"," ('should', 'help'): 20,\n"," ('help', 'the'): 149,\n"," ('the', 'lady'): 30,\n"," ('lady', 'burn'): 1,\n"," ('burn', 'her'): 3,\n"," ('her', 'stuff'): 2,\n"," ('stuff', 'somewhere'): 1,\n"," ('somewhere', 'else'): 53,\n"," ('else', '</s>'): 327,\n"," ('<s>', 'thats'): 2145,\n"," ('thats', 'it'): 88,\n"," ('it', '</s>'): 5030,\n"," ('<s>', 'as'): 1438,\n"," ('as', 'if'): 353,\n"," ('if', 'me'): 2,\n"," ('me', 'shutting'): 1,\n"," ('shutting', 'up'): 2,\n"," ('up', 'matters'): 1,\n"," ('matters', '</s>'): 78,\n"," ('<s>', 'that'): 2710,\n"," ('that', 'mob'): 3,\n"," ('mob', 'gon'): 2,\n"," ('gon', 'na'): 903,\n"," ('na', 'just'): 5,\n"," ('just', 'sound'): 8,\n"," ('sound', 'over'): 1,\n"," ('over', 'my'): 21,\n"," ('my', 'voice'): 9,\n"," ('voice', '</s>'): 32,\n"," ('<s>', 'didn'): 40,\n"," ('didn', '’'): 578,\n"," ('’', 't'): 6521,\n"," ('t', 'sun'): 1,\n"," ('sun', 'yatsen'): 6,\n"," ('yatsen', 'establish'): 1,\n"," ('establish', 'the'): 4,\n"," ('the', 'nation'): 146,\n"," ('nation', 'of'): 41,\n"," ('of', 'china'): 662,\n"," ('china', 'he'): 3,\n"," ('he', 'was'): 1287,\n"," ('was', 'instrumental'): 4,\n"," ('instrumental', 'in'): 3,\n"," ('in', 'the'): 11579,\n"," ('the', 'overthrow'): 2,\n"," ('overthrow', 'of'): 4,\n"," ('the', 'qing'): 65,\n"," ('qing', 'dynasty'): 35,\n"," ('dynasty', 'and'): 6,\n"," ('and', 'turning'): 10,\n"," ('turning', 'it'): 4,\n"," ('it', 'into'): 71,\n"," ('into', 'modern'): 2,\n"," ('modern', 'china'): 14,\n"," ('china', '</s>'): 1577,\n"," ('<s>', 'and'): 5492,\n"," ('and', 'yeah'): 68,\n"," ('yeah', 'i'): 270,\n"," ('i', '’'): 2268,\n"," ('’', 'm'): 1532,\n"," ('m', 'sure'): 103,\n"," ('sure', 'taiwan'): 1,\n"," ('taiwan', 'if'): 2,\n"," ('if', 'they'): 1630,\n"," ('they', 'had'): 400,\n"," ('had', 'the'): 303,\n"," ('the', 'population'): 323,\n"," ('population', 'size'): 4,\n"," ('size', 'and'): 13,\n"," ('and', 'resources'): 49,\n"," ('resources', 'of'): 10,\n"," ('of', 'mainland'): 12,\n"," ('mainland', 'china'): 79,\n"," ('china', 'could'): 18,\n"," ('could', 'advance'): 1,\n"," ('advance', 'to'): 1,\n"," ('to', 'the'): 6078,\n"," ('the', 'point'): 658,\n"," ('point', 'where'): 52,\n"," ('where', 'they'): 257,\n"," ('they', 'could'): 340,\n"," ('could', 'invent'): 1,\n"," ('invent', 'what'): 1,\n"," ('what', 'current'): 1,\n"," ('current', 'china'): 3,\n"," ('china', 'can'): 59,\n"," ('can', 'do'): 564,\n"," ('do', 'now'): 30,\n"," ('now', '</s>'): 1639,\n"," ('<s>', 'taiwan'): 141,\n"," ('taiwan', 'did'): 2,\n"," ('did', 'invent'): 3,\n"," ('invent', 'the'): 1,\n"," ('the', 'cross'): 7,\n"," ('cross', 'molecular'): 1,\n"," ('molecular', 'beam'): 1,\n"," ('beam',\n","  'apparatushttpsenmwikipediaorgwikilistoftaiwaneseinventionsanddiscoveries'): 1,\n"," ('apparatushttpsenmwikipediaorgwikilistoftaiwaneseinventionsanddiscoveries',\n","  'and'): 1,\n"," ('and', 'i'): 2322,\n"," ('i', 'think'): 2662,\n"," ('think', 'taiwan'): 7,\n"," ('taiwan', 'can'): 9,\n"," ('can', 'resist'): 3,\n"," ('resist', 'us'): 1,\n"," ('us',\n","  'influencehttpsenmwikipediaorgwikitaiwan–unitedstatesrelationsnotableissues'): 1,\n"," ('influencehttpsenmwikipediaorgwikitaiwan–unitedstatesrelationsnotableissues',\n","  'l'): 1,\n"," ('l', 'mean'): 1,\n"," ('mean', 'taiwan'): 1,\n"," ('taiwan', 'regularly'): 1,\n"," ('regularly', 'resists'): 1,\n"," ('resists', 'influence'): 1,\n"," ('influence', 'from'): 12,\n"," ('from', 'china'): 203,\n"," ('china', 'on'): 26,\n"," ('on', 'a'): 1078,\n"," ('a', 'daily'): 47,\n"," ('daily', 'basis'): 47,\n"," ('basis', '</s>'): 63,\n"," ('<s>', 'the'): 10904,\n"," ('the', 'ned'): 2,\n"," ('ned', 'is'): 1,\n"," ('is', 'a'): 5517,\n"," ('a', 'nonprofit'): 2,\n"," ('nonprofit', 'organization'): 1,\n"," ('organization', 'that'): 23,\n"," ('that', 'distributes'): 1,\n"," ('distributes', 'fund'): 1,\n"," ('fund', 'to'): 7,\n"," ('to', 'nongovernmental'): 1,\n"," ('nongovernmental', 'organizations'): 1,\n"," ('organizations', 'that'): 11,\n"," ('that', 'promote'): 2,\n"," ('promote', 'voting'): 1,\n"," ('voting', '</s>'): 20,\n"," ('ned', 'while'): 1,\n"," ('while', 'getting'): 5,\n"," ('getting', 'its'): 4,\n"," ('its', 'funding'): 1,\n"," ('funding', 'from'): 7,\n"," ('from', 'the'): 2607,\n"," ('the', 'us'): 3234,\n"," ('us', 'government'): 121,\n"," ('government', 'is'): 350,\n"," ('is', 'not'): 3245,\n"," ('not', 'an'): 310,\n"," ('an', 'instrument'): 3,\n"," ('instrument', 'of'): 6,\n"," ('of', 'us'): 659,\n"," ('us', 'foreign'): 18,\n"," ('foreign', 'policy'): 94,\n"," ('policy', 'it'): 4,\n"," ('it', 'has'): 909,\n"," ('has', 'funded'): 5,\n"," ('funded', 'prodemocratic'): 1,\n"," ('prodemocratic', 'organizations'): 1,\n"," ('organizations', 'even'): 2,\n"," ('even', 'when'): 120,\n"," ('us', 'supported'): 7,\n"," ('supported', 'dictatorships'): 2,\n"," ('dictatorships', 'in'): 2,\n"," ('in', 'those'): 111,\n"," ('those', 'very'): 7,\n"," ('very', 'regions'): 1,\n"," ('regions', 'and'): 5,\n"," ('and', 'what'): 435,\n"," ('what', 'you'): 1093,\n"," ('you', 'said'): 341,\n"," ('said', 'about'): 45,\n"," ('about', 'the'): 1791,\n"," ('the', 'american'): 175,\n"," ('american', 'tradition'): 2,\n"," ('tradition', 'of'): 12,\n"," ('of', 'helping'): 12,\n"," ('helping', 'the'): 43,\n"," ('the', 'enemy'): 88,\n"," ('enemy', 'of'): 32,\n"," ('of', 'my'): 804,\n"," ('my', 'enemy'): 5,\n"," ('enemy', 'is'): 17,\n"," ('is', 'sadly'): 10,\n"," ('sadly', 'very'): 1,\n"," ('very', 'true'): 31,\n"," ('true', '</s>'): 564,\n"," ('and', 'isn'): 7,\n"," ('isn', '’'): 550,\n"," ('t', 'that'): 37,\n"," ('that', 'what'): 124,\n"," ('what', 'happened'): 344,\n"," ('happened', 'to'): 245,\n"," ('the', 'kuomintang'): 11,\n"," ('kuomintang', 'in'): 1,\n"," ('in', 'china'): 1615,\n"," ('china', 'didn'): 4,\n"," ('t', 'the'): 70,\n"," ('the', 'ccp'): 1162,\n"," ('ccp', 'work'): 1,\n"," ('work', 'with'): 104,\n"," ('with', 'them'): 383,\n"," ('them', 'for'): 196,\n"," ('for', 'years'): 148,\n"," ('years', 'to'): 94,\n"," ('to', 'stop'): 471,\n"," ('stop', 'japan'): 1,\n"," ('japan', '</s>'): 78,\n"," ('and', 'then'): 988,\n"," ('then', 'afterwords'): 1,\n"," ('afterwords', 'pushed'): 1,\n"," ('pushed', 'them'): 5,\n"," ('them', 'out'): 141,\n"," ('china', 'into'): 12,\n"," ('into', 'taiwan'): 3,\n"," ('taiwan', 'again'): 3,\n"," ('again', 'i'): 84,\n"," ('i', 'don'): 729,\n"," ('don', '’'): 2373,\n"," ('t', 'hate'): 10,\n"," ('hate', 'the'): 149,\n"," ('the', 'people'): 1924,\n"," ('people', 'of'): 556,\n"," ('china', 'that'): 58,\n"," ('that', 'would'): 420,\n"," ('would', 'be'): 2172,\n"," ('be', 'saying'): 20,\n"," ('saying', 'i'): 51,\n"," ('i', 'hate'): 257,\n"," ('hate', 'most'): 3,\n"," ('most', 'of'): 1323,\n"," ('my', 'family'): 232,\n"," ('family', '</s>'): 269,\n"," ('the', 'authoritarian'): 13,\n"," ('authoritarian', 'and'): 11,\n"," ('and', 'corrupt'): 21,\n"," ('corrupt', 'government'): 33,\n"," ('government', 'that'): 77,\n"," ('that', 'runs'): 7,\n"," ('runs', 'everything'): 2,\n"," ('everything', 'just'): 11,\n"," ('just', 'as'): 312,\n"," ('as', 'much'): 485,\n"," ('much', 'as'): 320,\n"," ('as', 'i'): 610,\n"," ('i', 'dislike'): 16,\n"," ('dislike', 'trumps'): 1,\n"," ('trumps', '</s>'): 2,\n"," ('<s>', 'wow'): 500,\n"," ('wow', 'really'): 5,\n"," ('really', 'considering'): 2,\n"," ('considering', 'most'): 4,\n"," ('of', 'pti'): 17,\n"," ('pti', 'party'): 2,\n"," ('party', 'members'): 27,\n"," ('members', 'are'): 22,\n"," ('are', 'former'): 4,\n"," ('former', 'pmln'): 2,\n"," ('pmln', 'and'): 7,\n"," ('and', 'ppp'): 8,\n"," ('ppp', 'members'): 2,\n"," ('members', 'what'): 2,\n"," ('what', 'difference'): 11,\n"," ('difference', 'does'): 11,\n"," ('does', 'it'): 328,\n"," ('it', 'actually'): 63,\n"," ('actually', 'make'): 23,\n"," ('make', '</s>'): 68,\n"," ('you', 'know'): 1190,\n"," ('know', 'just'): 7,\n"," ('just', 'yesterday'): 17,\n"," ('yesterday', 'the'): 4,\n"," ('the', 'new'): 319,\n"," ('new', 'budget'): 2,\n"," ('budget', 'was'): 2,\n"," ('was', 'released'): 13,\n"," ('released', 'which'): 1,\n"," ('which', 'has'): 136,\n"," ('has', 'now'): 32,\n"," ('now', 'recognised'): 1,\n"," ('recognised', 'mental'): 1,\n"," ('mental', 'health'): 188,\n"," ('health', 'problems'): 19,\n"," ('problems', 'for'): 9,\n"," ('for', 'the'): 4246,\n"," ('the', 'first'): 1208,\n"," ('first', 'time'): 212,\n"," ('time', 'and'): 324,\n"," ('and', 'whenever'): 10,\n"," ('whenever', 'any'): 2,\n"," ('any', 'channel'): 3,\n"," ('channel', 'started'): 1,\n"," ('started', 'talking'): 9,\n"," ('talking', 'about'): 1153,\n"," ('about', 'it'): 986,\n"," ('it', 'my'): 18,\n"," ('my', 'parents'): 222,\n"," ('parents', 'kept'): 1,\n"," ('kept', 'changing'): 1,\n"," ('changing', 'it'): 5,\n"," ('i', 'had'): 614,\n"," ('had', 'a'): 756,\n"," ('a', 'good'): 1288,\n"," ('good', 'little'): 3,\n"," ('little', 'fight'): 1,\n"," ('fight', 'with'): 38,\n"," ('them', 'i'): 61,\n"," ('i', 'mean'): 985,\n"," ('mean', 'come'): 5,\n"," ('come', 'on'): 129,\n"," ('on', 'these'): 104,\n"," ('these', 'problems'): 33,\n"," ('problems', 'are'): 22,\n"," ('are', 'real'): 46,\n"," ('real', 'and'): 34,\n"," ('and', 'not'): 982,\n"," ('not', 'contagious'): 3,\n"," ('contagious', '</s>'): 9,\n"," ('<s>', 'isn'): 46,\n"," ('that', 'line'): 22,\n"," ('line', 'from'): 7,\n"," ('from', 'cod'): 1,\n"," ('cod', '</s>'): 2,\n"," ('<s>', 'shaghufta'): 1,\n"," ('shaghufta', 'from'): 1,\n"," ('from', 'lums'): 5,\n"," ('lums', 'definitely'): 1,\n"," ('definitely', 'is'): 17,\n"," ('is', 'an'): 863,\n"," ('an', 'army'): 70,\n"," ('army', 'brat'): 5,\n"," ('brat', '</s>'): 7,\n"," ('<s>', 'opportunity'): 3,\n"," ('opportunity', 'creator'): 1,\n"," ('creator', 'banna'): 1,\n"," ('banna', 'padega'): 1,\n"," ('padega', 'ban'): 1,\n"," ('ban', 'paoge'): 1,\n"," ('paoge', '</s>'): 1,\n"," ('<s>', 'yahi'): 1,\n"," ('yahi', 'samasya'): 1,\n"," ('samasya', 'hai'): 1,\n"," ('hai', 'parents'): 1,\n"," ('parents', 'want'): 6,\n"," ('want', 'opportunities'): 1,\n"," ('opportunities', 'not'): 2,\n"," ('not', 'opportunity'): 1,\n"," ('opportunity', 'creators'): 1,\n"," ('creators', 'only'): 1,\n"," ('only', 'if'): 85,\n"," ('a', 'broader'): 5,\n"," ('broader', 'mindsetthered'): 1,\n"," ('mindsetthered', 'be'): 1,\n"," ('be', 'more'): 334,\n"," ('more', 'creativity'): 1,\n"," ('creativity', 'job'): 1,\n"," ('job', 'security'): 7,\n"," ('security', 'and'): 29,\n"," ('and', 'freedom'): 54,\n"," ('freedom', 'in'): 9,\n"," ('the', 'society'): 164,\n"," ('society', '</s>'): 324,\n"," ('i', 'am'): 4362,\n"," ('am', 'sure'): 128,\n"," ('sure', 'your'): 29,\n"," ('your', 'hand'): 21,\n"," ('hand', 'can'): 4,\n"," ('do', 'better'): 46,\n"," ('better', 'edit'): 2,\n"," ('edit', 'is'): 3,\n"," ('is', 'your'): 234,\n"," ('hand', 'muslim'): 3,\n"," ('muslim', '</s>'): 191,\n"," ('<s>', 'dont'): 991,\n"," ('dont', 'compare'): 11,\n"," ('compare', 'the'): 41,\n"," ('the', 'idiotic'): 7,\n"," ('idiotic', 'us'): 1,\n"," ('us', 'insurrection'): 1,\n"," ('insurrection', 'to'): 1,\n"," ('to', 'a'): 1370,\n"," ('a', 'noble'): 13,\n"," ('noble', 'one'): 3,\n"," ('one', 'like'): 17,\n"," ('like', 'sls'): 1,\n"," ('sls', '</s>'): 1,\n"," ('<s>', 'shame'): 80,\n"," ('shame', 'on'): 80,\n"," ('on', 'those'): 76,\n"," ('those', 'who'): 591,\n"," ('who', 'booed'): 1,\n"," ('booed', 'the'): 1,\n"," ('the', 'anthem'): 6,\n"," ('anthem', 'regardless'): 1,\n"," ('regardless', 'which'): 3,\n"," ('which', 'nations'): 1,\n"," ('nations', 'anthem'): 1,\n"," ('anthem', 'is'): 3,\n"," ('is', 'played'): 11,\n"," ('played', '</s>'): 23,\n"," ('<s>', 'more'): 274,\n"," ('more', 'shame'): 1,\n"," ('on', 'hk'): 8,\n"," ('hk', 'who'): 1,\n"," ('who', 'betray'): 1,\n"," ('betray', 'their'): 1,\n"," ('their', 'mother'): 22,\n"," ('mother', 'land'): 2,\n"," ('land', 'for'): 9,\n"," ('for', 'they'): 16,\n"," ('they', 'have'): 1788,\n"," ('have', 'forgotten'): 19,\n"," ('forgotten', 'how'): 3,\n"," ('how', 'hk'): 2,\n"," ('hk', 'was'): 7,\n"," ('was', 'hijacked'): 2,\n"," ('hijacked', 'by'): 5,\n"," ('by', 'pirates'): 1,\n"," ('pirates', 'of'): 2,\n"," ('of', 'south'): 53,\n"," ('south', 'seas'): 1,\n"," ('seas', 'and'): 1,\n"," ('and', 'british'): 15,\n"," ('british', 'in'): 7,\n"," ('the', 'name'): 400,\n"," ('name', 'free'): 1,\n"," ('free', 'trade'): 13,\n"," ('trade', 'of'): 2,\n"," ('of', 'opioids'): 1,\n"," ('opioids', '</s>'): 2,\n"," ('<s>', 'pathetic'): 35,\n"," ('pathetic', '</s>'): 85,\n"," ('im', 'straight'): 2,\n"," ('straight', 'up'): 93,\n"," ('up', 'vibing'): 1,\n"," ('vibing', 'to'): 1,\n"," ('to', 'this'): 728,\n"," ('this', 'on'): 161,\n"," ('on', 'the'): 4326,\n"," ('the', 'toilet'): 18,\n"," ('toilet', '</s>'): 16,\n"," ('<s>', 'byjus'): 33,\n"," ('byjus', 'is'): 29,\n"," ('is', 'basically'): 123,\n"," ('basically', 'kota'): 1,\n"," ('kota', 'but'): 1,\n"," ('but', 'on'): 52,\n"," ('a', 'much'): 162,\n"," ('much', 'larger'): 27,\n"," ('larger', 'scale'): 17,\n"," ('scale', '</s>'): 51,\n"," ('<s>', 'it'): 6138,\n"," ('it', 'should'): 229,\n"," ('should', 'be'): 1631,\n"," ('be', 'like'): 180,\n"," ('like', 'lets'): 4,\n"," ('lets', 'forget'): 5,\n"," ('forget', 'about'): 67,\n"," ('about', 'all'): 62,\n"," ('all', 'other'): 113,\n"," ('other', 'issues'): 20,\n"," ('issues', 'and'): 46,\n"," ('and', 'lets'): 38,\n"," ('lets', 'stay'): 3,\n"," ('stay', 'away'): 41,\n"," ('away', 'from'): 337,\n"," ('from', 'each'): 22,\n"," ('each', 'other'): 439,\n"," ('other', 'to'): 27,\n"," ('to', 'beat'): 63,\n"," ('beat', 'this'): 4,\n"," ('this', 'epidemic'): 3,\n"," ('epidemic', '</s>'): 3,\n"," ('<s>', 'we'): 3816,\n"," ('we', 'need'): 643,\n"," ('need', 'too'): 3,\n"," ('too', 'be'): 2,\n"," ('be', 'doing'): 72,\n"," ('doing', 'more'): 20,\n"," ('more', '</s>'): 403,\n"," ('<s>', 'okay'): 203,\n"," ('okay', 'yeah'): 4,\n"," ('i', 'checked'): 73,\n"," ('checked', 'like'): 2,\n"," ('like', 'early'): 2,\n"," ('early', '2018'): 1,\n"," ('2018', '</s>'): 20,\n"," ('<s>', 'bing'): 8,\n"," ('bing', 'was'): 1,\n"," ('was', 'banned'): 29,\n"," ('banned', 'just'): 1,\n"," ('was', 'leaving'): 4,\n"," ('leaving', 'i'): 2,\n"," ('think', '</s>'): 264,\n"," ('seems', 'like'): 357,\n"," ('like', 'every'): 43,\n"," ('every', 'year'): 90,\n"," ('year', 'a'): 4,\n"," ('a', 'few'): 1208,\n"," ('few', 'more'): 31,\n"," ('more', 'go'): 1,\n"," ('go', '</s>'): 245,\n"," ('<s>', 'can'): 875,\n"," ('can', 'we'): 189,\n"," ('we', 'make'): 46,\n"," ('make', 'her'): 34,\n"," ('her', 'popular'): 1,\n"," ('popular', 'like'): 2,\n"," ('like', 'donald'): 3,\n"," ('donald', 'trump'): 52,\n"," ('trump', 'i'): 2,\n"," ('mean', 'in'): 17,\n"," ('in', 'google'): 10,\n"," ('google', 'image'): 6,\n"," ('image', 'search'): 4,\n"," ('search', 'trump'): 1,\n"," ('trump', 'tops'): 1,\n"," ('tops', 'when'): 1,\n"," ('when', 'you'): 931,\n"," ('you', 'search'): 24,\n"," ('search', 'for'): 56,\n"," ('for', 'idiot'): 1,\n"," ('idiot', '</s>'): 115,\n"," ('we', 'do'): 352,\n"," ('do', 'something'): 245,\n"," ('something', 'like'): 264,\n"," ('like', 'that'): 704,\n"," ('that', '</s>'): 2482,\n"," ('i', 'know'): 1453,\n"," ('know', 'this'): 159,\n"," ('this', 'is'): 5768,\n"," ('not', 'immediately'): 6,\n"," ('immediately', 'effective'): 1,\n"," ('effective', 'might'): 1,\n"," ('might', 'not'): 175,\n"," ('not', 'help'): 33,\n"," ('help', 'change'): 2,\n"," ('change', 'the'): 212,\n"," ('the', 'current'): 408,\n"," ('current', 'situation'): 72,\n"," ('situation', 'at'): 15,\n"," ('at', 'all'): 956,\n"," ('all', '</s>'): 790,\n"," ('<s>', 'however'): 492,\n"," ('however', 'its'): 8,\n"," ('its', 'not'): 1760,\n"," ('not', 'going'): 290,\n"," ('to', 'be'): 6498,\n"," ('be', 'comfortable'): 5,\n"," ('comfortable', 'for'): 3,\n"," ('for', 'an'): 184,\n"," ('an', 'extremely'): 58,\n"," ('extremely', 'vindictive'): 1,\n"," ('vindictive', 'and'): 2,\n"," ('and', 'hateful'): 4,\n"," ('hateful', 'person'): 1,\n"," ('person', 'like'): 25,\n"," ('like', 'her'): 38,\n"," ('her', '</s>'): 265,\n"," ('<s>', 'werent'): 11,\n"," ('werent', 'they'): 8,\n"," ('they', 'saying'): 6,\n"," ('saying', 'youre'): 10,\n"," ('youre', 'next'): 1,\n"," ('next', 'in'): 4,\n"," ('in', 'that'): 645,\n"," ('that', 'video'): 41,\n"," ('video', 'jokingly'): 1,\n"," ('jokingly', '</s>'): 1,\n"," ('<s>', 'yes'): 1592,\n"," ('yes', '</s>'): 441,\n"," ('am', 'content'): 1,\n"," ('content', 'now'): 1,\n"," ('i', 'wish'): 448,\n"," ('wish', 'they'): 30,\n"," ('had', 'taken'): 13,\n"," ('taken', 'the'): 24,\n"," ('the', 'tinkle'): 2,\n"," ('tinkle', 'characters'): 1,\n"," ('characters', 'and'): 11,\n"," ('and', 'done'): 9,\n"," ('done', 'more'): 35,\n"," ('more', 'with'): 24,\n"," ('them', '</s>'): 2283,\n"," ('<s>', 'characters'): 2,\n"," ('characters', 'like'): 5,\n"," ('like', 'shikari'): 1,\n"," ('shikari', 'shambhu'): 1,\n"," ('shambhu', 'and'): 1,\n"," ('and', 'suppandi'): 1,\n"," ('suppandi', 'could'): 1,\n"," ('could', 'have'): 465,\n"," ('have', 'become'): 44,\n"," ('become', 'huge'): 1,\n"," ('huge', 'if'): 1,\n"," ('if', 'people'): 166,\n"," ('people', 'had'): 45,\n"," ('had', 'just'): 25,\n"," ('just', 'taken'): 6,\n"," ('taken', 'more'): 5,\n"," ('more', 'care'): 5,\n"," ('care', 'of'): 178,\n"," ('of', 'them'): 1329,\n"," ('them', 'developed'): 1,\n"," ('developed', 'them'): 1,\n"," ('them', 'and'): 438,\n"," ('and', 'given'): 41,\n"," ('given', 'better'): 1,\n"," ('better', 'storylines'): 1,\n"," ('storylines', '</s>'): 2,\n"," ('<s>', 'funny'): 97,\n"," ('funny', 'you'): 12,\n"," ('are', 'preaching'): 3,\n"," ('preaching', 'to'): 12,\n"," ('the', 'choir'): 6,\n"," ('choir', 'here'): 1,\n"," ('here', '</s>'): 1555,\n"," ('i', 'have'): 2424,\n"," ('have', 'often'): 8,\n"," ('often', 'considered'): 2,\n"," ('considered', 'how'): 3,\n"," ('how', 'it'): 282,\n"," ('it', 'is'): 4440,\n"," ('is', 'that'): 1738,\n"," ('that', 'the'): 2637,\n"," ('the', 'extreme'): 35,\n"," ('extreme', 'left'): 2,\n"," ('left', 'and'): 75,\n"," ('extreme', 'right'): 6,\n"," ('right', 'are'): 8,\n"," ('are', 'actually'): 120,\n"," ('actually', 'the'): 59,\n"," ('the', 'only'): 1439,\n"," ('only', 'ones'): 50,\n"," ('ones', 'who'): 203,\n"," ('who', 'truly'): 7,\n"," ('truly', 'care'): 4,\n"," ('care', 'about'): 509,\n"," ('about', 'their'): 200,\n"," ('their', 'citizens'): 45,\n"," ('citizens', 'more'): 4,\n"," ('more', 'than'): 1130,\n"," ('than', 'the'): 803,\n"," ('the', 'state'): 508,\n"," ('state', 'and'): 119,\n"," ('and', 'policies'): 10,\n"," ('policies', '</s>'): 70,\n"," ('i', 'utterly'): 1,\n"," ('utterly', 'disagree'): 1,\n"," ('disagree', 'with'): 159,\n"," ('with', 'you'): 661,\n"," ('you', 'that'): 243,\n"," ('the', 'leftists'): 7,\n"," ('leftists', 'offer'): 1,\n"," ('offer', 'anything'): 2,\n"," ('anything', 'but'): 95,\n"," ('but', 'pain'): 2,\n"," ('pain', 'and'): 23,\n"," ('and', 'suffering'): 18,\n"," ('suffering', 'to'): 6,\n"," ('to', 'their'): 623,\n"," ('their', 'people'): 86,\n"," ('people', 'in'): 1100,\n"," ('the', 'long'): 98,\n"," ('long', 'run'): 39,\n"," ('run', 'this'): 9,\n"," ('is', 'both'): 21,\n"," ('both', 'the'): 114,\n"," ('the', 'national'): 169,\n"," ('national', 'socialists'): 1,\n"," ('socialists', 'and'): 5,\n"," ('the', 'communist'): 93,\n"," ('communist', 'socialists'): 1,\n"," ('socialists', 'but'): 2,\n"," ('but', 'despite'): 4,\n"," ('despite', 'that'): 11,\n"," ('that', 'disagreement'): 2,\n"," ('disagreement', 'i'): 1,\n"," ('i', 'do'): 744,\n"," ('do', 'keep'): 5,\n"," ('keep', 'seeing'): 7,\n"," ('seeing', 'that'): 18,\n"," ('that', 'its'): 351,\n"," ('its', 'people'): 127,\n"," ('people', 'on'): 243,\n"," ('extreme', 'that'): 3,\n"," ('that', 'see'): 4,\n"," ('see', 'the'): 671,\n"," ('the', 'ugly'): 12,\n"," ('ugly', 'machine'): 1,\n"," ('machine', 'in'): 1,\n"," ('the', 'middle'): 412,\n"," ('middle', 'for'): 1,\n"," ('the', 'monster'): 9,\n"," ('monster', 'it'): 1,\n"," ('it', 'isx000d'): 3,\n"," ('isx000d', 'x000d'): 8,\n"," ('x000d', 'x200bx000d'): 42,\n"," ('x200bx000d', 'x000d'): 43,\n"," ('x000d', 'biden'): 4,\n"," ('biden', 'will'): 5,\n"," ('will', 'be'): 2067,\n"," ('be', 'dead'): 20,\n"," ('dead', 'and'): 24,\n"," ('and', 'kamala'): 2,\n"," ('kamala', 'will'): 2,\n"," ('will', 'reign'): 3,\n"," ('reign', 'for'): 1,\n"," ('for', '12'): 12,\n"," ('12', 'years'): 22,\n"," ('years', 'and'): 215,\n"," ('and', 'it'): 1115,\n"," ('it', 'will'): 745,\n"," ('be', 'a'): 1910,\n"," ('a', 'nightmare'): 20,\n"," ('nightmare', '</s>'): 13,\n"," ('<s>', 'shes'): 104,\n"," ('shes', 'worse'): 1,\n"," ('worse', 'than'): 224,\n"," ('than', 'a'): 321,\n"," ('a', 'dictator'): 31,\n"," ('dictator', 'shes'): 1,\n"," ('shes', 'a'): 49,\n"," ('a', 'plutocratic'): 1,\n"," ('plutocratic', 'oligarch'): 1,\n"," ('oligarch', 'and'): 2,\n"," ('and', 'she'): 159,\n"," ('she', 'only'): 9,\n"," ('only', 'cares'): 14,\n"," ('cares', 'about'): 125,\n"," ('about', 'selfenrichment'): 1,\n"," ('selfenrichment', 'and'): 1,\n"," ('and', 'power'): 51,\n"," ('power', 'which'): 7,\n"," ('which', 'is'): 1452,\n"," ('is', 'honestly'): 17,\n"," ('honestly', 'means'): 1,\n"," ('means', 'shes'): 1,\n"," ('shes', 'likely'): 1,\n"," ('likely', 'to'): 163,\n"," ('to', 'avoid'): 193,\n"," ('avoid', 'making'): 4,\n"," ('making', 'missteps'): 1,\n"," ('missteps', 'what'): 1,\n"," ('what', 'cost'): 5,\n"," ('cost', 'her'): 2,\n"," ('her', 'the'): 20,\n"," ('the', 'job'): 101,\n"," ('job', 'while'): 2,\n"," ('while', 'she'): 10,\n"," ('she', 'keeps'): 3,\n"," ('keeps', 'the'): 16,\n"," ('us', 'war'): 1,\n"," ('war', 'machine'): 6,\n"," ('machine', 'going'): 1,\n"," ('going', 'brrrrrr'): 1,\n"," ('brrrrrr', '</s>'): 1,\n"," ('m', 'well'): 2,\n"," ('well', 'aware'): 285,\n"," ('aware', '</s>'): 16,\n"," ('i', 'understand'): 305,\n"," ('understand', 'your'): 63,\n"," ('your', 'standpoint'): 2,\n"," ('standpoint', 'but'): 2,\n"," ('but', 'the'): 1458,\n"," ('the', 'way'): 941,\n"," ('way', 'you'): 130,\n"," ('you', 'respond'): 9,\n"," ('respond', 'to'): 58,\n"," ('to', 'something'): 53,\n"," ('something', 'you'): 95,\n"," ('you', 'don'): 283,\n"," ('t', 'agree'): 36,\n"," ('agree', 'with'): 605,\n"," ('with', 'is'): 23,\n"," ('is', 'what'): 679,\n"," ('what', 'i'): 943,\n"," ('m', 'talking'): 22,\n"," ('about', '</s>'): 485,\n"," ('it', 'really'): 164,\n"," ('really', 'seems'): 9,\n"," ('like', 'you'): 812,\n"," ('you', 'focus'): 6,\n"," ('focus', 'too'): 3,\n"," ('too', 'much'): 408,\n"," ('much', 'on'): 29,\n"," ('on', 'what'): 206,\n"," ('you', '’'): 1122,\n"," ('’', 're'): 1479,\n"," ('re', 'offended'): 4,\n"," ('offended', 'by'): 47,\n"," ('by', 'and'): 39,\n"," ('it', 'makes'): 255,\n"," ('makes', 'it'): 178,\n"," ('it', 'so'): 192,\n"," ('so', 'you'): 517,\n"," ('re', 'unwilling'): 2,\n"," ('unwilling', 'to'): 26,\n"," ('to', 'take'): 831,\n"," ('take', 'in'): 17,\n"," ('in', 'any'): 391,\n"," ('any', 'new'): 13,\n"," ('new', 'information'): 9,\n"," ('information', '</s>'): 184,\n"," ('it', '’'): 3066,\n"," ('’', 's'): 6957,\n"," ('s', 'a'): 593,\n"," ('a', 'style'): 4,\n"," ('style', 'of'): 31,\n"," ('of', 'communication'): 15,\n"," ('communication', 'that'): 3,\n"," ('that', 'won'): 10,\n"," ('won', '’'): 268,\n"," ('t', 'allow'): 11,\n"," ('allow', 'growth'): 2,\n"," ('growth', '</s>'): 38,\n"," ('how', 'would'): 98,\n"," ('would', 'you'): 346,\n"," ('know', 'aren'): 2,\n"," ('aren', '’'): 294,\n"," ('t', 'you'): 102,\n"," ('you', 'british'): 2,\n"," ('british', '</s>'): 58,\n"," ('<s>', 'so'): 3816,\n"," ('so', 'i'): 833,\n"," ('i', 'havent'): 174,\n"," ('havent', 'been'): 75,\n"," ('been', 'debating'): 3,\n"," ('debating', 'with'): 7,\n"," ('with', 'an'): 184,\n"," ('an', 'indian'): 399,\n"," ('indian', 'for'): 7,\n"," ('for', 'all'): 425,\n"," ('all', 'this'): 306,\n"," ('this', 'time'): 254,\n"," ('time', '</s>'): 1152,\n"," ('you', 'sure'): 80,\n"," ('sure', 'sounded'): 2,\n"," ('sounded', 'like'): 11,\n"," ('like', 'one'): 48,\n"," ('<s>', 'had'): 116,\n"," ('had', 'me'): 27,\n"," ('me', 'fooled'): 3,\n"," ('fooled', 'there'): 2,\n"," ('there', '</s>'): 1175,\n"," ('<s>', 'to'): 877,\n"," ('to', 'answer'): 104,\n"," ('answer', 'your'): 27,\n"," ('your', 'question'): 63,\n"," ('question', 'why'): 30,\n"," ('why', 'wont'): 7,\n"," ('wont', 'india'): 2,\n"," ('india', 'will'): 73,\n"," ('will', 'stick'): 6,\n"," ('stick', 'to'): 63,\n"," ('a', 'no'): 29,\n"," ('no', 'first'): 5,\n"," ('first', 'use'): 6,\n"," ('use', 'here'): 2,\n"," ('here', 'is'): 421,\n"," ('a', 'link'): 230,\n"," ('link', 'to'): 298,\n"," ('a', 'page'): 11,\n"," ('page',\n","  'httpsforeignpolicycom20201023indianuclearnofirstusestrikechinapakistanhttpsforeignpolicycom20201023indianuclearnofirstusestrikechinapakistan'): 2,\n"," ('httpsforeignpolicycom20201023indianuclearnofirstusestrikechinapakistanhttpsforeignpolicycom20201023indianuclearnofirstusestrikechinapakistan',\n","  'x200b'): 2,\n"," ('x200b', 'a'): 4,\n"," ('a', 'summary'): 13,\n"," ('summary', 'the'): 2,\n"," ('the', 'country'): 1520,\n"," ('country', 'has'): 158,\n"," ('has', 'good'): 26,\n"," ('good', 'reason'): 39,\n"," ('reason', 'to'): 175,\n"," ('to', 'want'): 39,\n"," ('want', 'firststrike'): 2,\n"," ('firststrike', 'capabilities'): 2,\n"," ('capabilities', '</s>'): 15,\n"," ('<s>', 'but'): 5047,\n"," ('the', 'actual'): 272,\n"," ('actual', 'state'): 3,\n"," ('state', 'of'): 223,\n"," ('of', 'its'): 228,\n"," ('its', 'arsenal'): 2,\n"," ('arsenal', 'suggests'): 2,\n"," ('suggests', 'that'): 15,\n"," ('that', 'it'): 952,\n"," ('it', 'won'): 26,\n"," ('t', 'get'): 147,\n"," ('get', 'them'): 83,\n"," ('<s>', 'indias'): 37,\n"," ('indias', 'arsenal'): 2,\n"," ('arsenal', 'is'): 2,\n"," ('is', 'actually'): 265,\n"," ('actually', 'very'): 23,\n"," ('very', 'modest'): 2,\n"," ('modest', 'it'): 2,\n"," ('it', 'wouldnt'): 105,\n"," ('wouldnt', 'be'): 206,\n"," ('be', 'enough'): 45,\n"," ('enough', 'to'): 562,\n"," ('to', 'to'): 36,\n"," ...}"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["BIGRAM_MODEL.bigram_frequencies"]},{"cell_type":"markdown","metadata":{},"source":["### Using Good Turing Smoothing"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"r6IBVZkInO-p"},"outputs":[{"data":{"text/plain":["11066.516122294264"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["UNIGRAM_MODEL=unigram_model(train_unigram)\n","\n","count=0\n","total_perplex = 0\n","UNIGRAM_MODEL.calculate_new_word_count(UNIGRAM_MODEL.unigram_frequencies)\n","for data in test_unigram:\n","\n","    count+=1\n","    n = len(data)\n","    if(n == 0): continue\n","    unigram_perplex=0\n","    for word in data:\n","        unigram_perplex += np.log2(UNIGRAM_MODEL.calculate_probability_good_smooth(word))\n","\n","    unigram_perplex *= (-1/n)\n","    final_perplex = 2 ** unigram_perplex\n","    total_perplex += final_perplex\n","\n","\n","avg_perplex = total_perplex/count\n","avg_perplex"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"data":{"text/plain":["33521.19878052262"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["BIGRAM_MODEL=bigram_model(train_bigram)\n","total_perplex=0\n","count=0\n","BIGRAM_MODEL.calculate_new_word_count(BIGRAM_MODEL.bigram_frequencies)\n","for data in test_bigram:\n","    count+= 1\n","    bigram_perplex = 0\n","    n = len(data)\n","    if(n < 2): continue\n","\n","    for i in range(len(data)-1):\n","        bigram_perplex+=np.log2(BIGRAM_MODEL.calculate_probability_good_smooth((data[i],data[i+1])))\n","\n","    bigram_perplex *= (-1/n)\n","    final_perplex = 2 ** bigram_perplex\n","    total_perplex += final_perplex\n","\n","\n","Avg_perplex=total_perplex/count\n","Avg_perplex"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":["49041.468127868095"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["TRIGRAM_MODEL=trigram_model(train_trigram)\n","total_perplex=0\n","count=0\n","TRIGRAM_MODEL.calculate_new_word_count(TRIGRAM_MODEL.trigram_frequencies)\n","\n","for data in test_trigram:\n","    count+= 1\n","    trigram_perplex = 0\n","    n = len(data)\n","    if(n < 3): continue\n","\n","    for i in range(len(data)-2):\n","        trigram_perplex+=np.log2(TRIGRAM_MODEL.calculate_probability_good_smooth((data[i],data[i+1], data[i+2])))\n","\n","    trigram_perplex *= (-1/n)\n","    final_perplex = 2 ** trigram_perplex\n","    total_perplex += final_perplex\n","\n","\n","Avg_perplex=total_perplex/count\n","Avg_perplex"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"text/plain":["38494.41832202575"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["QUADGRAM_MODEL=quadgram_model(train_quadgram)\n","total_perplex=0\n","count=0\n","QUADGRAM_MODEL.calculate_new_word_count(QUADGRAM_MODEL.quadgram_frequencies)\n","\n","for data in test_quadgram:\n","    count+= 1\n","    quadgram_perplex = 0\n","    n = len(data)\n","    if(n < 4): continue\n","\n","    for i in range(len(data)-3):\n","        quadgram_perplex+=np.log2(QUADGRAM_MODEL.calculate_probability_good_smooth((data[i],data[i+1], data[i+2] , data[i+3])))\n","\n","    quadgram_perplex *= (-1/n)\n","    final_perplex = 2 ** quadgram_perplex\n","    total_perplex += final_perplex\n","\n","\n","Avg_perplex=total_perplex/count\n","Avg_perplex"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
